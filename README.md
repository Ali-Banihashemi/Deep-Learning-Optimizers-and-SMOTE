# Deep Learning Optimizers and SMOTE Example

This repository showcases my work on understanding and applying various optimizers for deep learning, handling imbalanced datasets using SMOTE, and building a deep neural network classification model. It is intended to demonstrate my skills and knowledge in these areas.

This was done for the AI course in 2024 at the University of Tehran under the instruction of Professor Khoshnevisan.

## Overview

### 1. Mathematical Intuition Behind Optimizers
This section explains the mathematical intuition behind three popular optimizers used in deep learning:
- **Stochastic Gradient Descent with Momentum (SGD+Momentum)**
- **Adagrad**
- **RMSprop**

### 2. Optimizer Performance Comparison
Here, I compare the performance of SGD+Momentum, Adagrad, and RMSprop in real-world applications, discussing the advantages and disadvantages of each when training neural networks.

### 3. Handling Imbalanced Datasets with SMOTE
This section addresses the issue of imbalanced datasets in machine learning. I explain the mathematics behind the Synthetic Minority Oversampling Technique (SMOTE) and demonstrate its application to improve the performance of deep neural network models with a Python and TensorFlow example.

### 4. Building a Classification Model
Using a provided dataset, I build a classification model employing a Deep Neural Network. This includes:
- **Implementing SMOTE** with Adagrad and RMSprop optimizers and comparing the results.
- **Plotting the loss and accuracy** for both training and validation phases.

## Instructions for Running the Code
1. Clone the repository:
    ```bash
    git clone https://github.com/yourusername/Deep-Learning-Optimizers-SMOTE.git
    cd Deep-Learning-Optimizers-SMOTE
    ```
2. Open the provided Jupyter notebook or Google Colab link in your browser.
3. Follow the instructions in the notebook to run each section of the project.

## Key Takeaways
- **Understanding Optimizers**: Gain insights into how different optimizers function and their impact on training neural networks.
- **SMOTE for Imbalanced Data**: Learn how to handle imbalanced datasets effectively using the SMOTE algorithm.
- **Practical Implementation**: See practical examples of applying these techniques using Python and TensorFlow.

## Contact
Feel free to reach out to me via [LinkedIn](https://www.linkedin.com/in/yourprofile) or [Email](mailto:youremail@example.com) for any questions or collaborations.

## License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments
Special thanks to the resources and communities that have supported my learning and growth in the field of AI and deep learning.

Happy Learning!
